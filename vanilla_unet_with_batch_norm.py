# -*- coding: utf-8 -*-
"""vanilla unet with batch norm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y595BVmd_jyihg9cPO7fX_W_czMopEex
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Heartloc3d

#pip install keras==2.9.0

#pip install tensorflow==2.9.0

import tensorflow as tf

#!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2

import keras
print(tf.__version__)
print(keras.__version__)

pip install segmentation_models_3D

import segmentation_models_3D as sm

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from skimage import io
import numpy as np
from matplotlib import pyplot as plt
from tensorflow.keras import backend as K
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

import os
import cv2

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = io.imread(os.path.join(folder,filename))
       
        if img is not None:
            images.append(img)
    return images

def load_masks_from_folder(folder):
    masks = []
    for filename in os.listdir(folder):
        img = io.imread(os.path.join(folder,filename))
        
        if img is not None:
            masks.append(img)
    return masks

pip install SimpleITK

import SimpleITK as sitk

images = load_images_from_folder('/content/drive/MyDrive/Heartloc3d/train/images')

masks = load_masks_from_folder('/content/drive/MyDrive/Heartloc3d/train/masks')

images = np.asarray(images, dtype='float32')

masks = np.asarray(masks, dtype='float32')

print(images.shape)

print(masks.shape)

from tensorflow.keras.utils import normalize

train_img = np.stack((images,)*3, axis=-1)
train_img = tf.keras.utils.normalize(train_img)

np.unique(masks)

masks.shape

'''from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
n, h, w, d = masks.shape
train_masks_reshaped = masks.reshape(-1,1)
train_masks_reshaped = train_masks_reshaped.ravel()
train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)
train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w, d)

train_masks= np.expand_dims(masks, axis=4)

train_mask_cat = to_categorical(train_masks, num_classes= 3)

X_train, X_test, y_train, y_test = train_test_split(train_img, train_mask_cat, test_size = 0.3, random_state = 51)

y_train.shape

def dice_coefficient(y_true, y_pred):
    smoothing_factor = 1
    flat_y_true = K.flatten(y_true)
    flat_y_pred = K.flatten(y_pred)
    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)

def dice_coefficient_loss(y_true, y_pred):
    return 1 - dice_coefficient(y_true, y_pred)

patch_size = 128
channels=2

LR = 0.0001
optim = tf.keras.optimizers.Adam(LR)

from keras.models import Model
from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda

from keras.layers import Activation, MaxPool2D, Concatenate


def conv_block(input, num_filters):
    x = Conv3D(num_filters, 3, padding="same")(input)
    x = BatchNormalization()(x)   #Not in the original network. 
    x = Activation("relu")(x)

    x = Conv3D(num_filters, 3, padding="same")(x)
    x = BatchNormalization()(x)  #Not in the original network
    x = Activation("relu")(x)

    return x

#Encoder block: Conv block followed by maxpooling


def encoder_block(input, num_filters):
    x = conv_block(input, num_filters)
    p = MaxPooling3D((2, 2, 2))(x)
    return x, p   

#Decoder block
#skip features gets input from encoder for concatenation

def decoder_block(input, skip_features, num_filters):
    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding="same")(input)
    x = Concatenate()([x, skip_features])
    x = conv_block(x, num_filters)
    return x

#Build Unet using the blocks
def build_unet(input_shape, n_classes):
    inputs = Input(input_shape)

    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    b1 = conv_block(p4, 1024) #Bridge

    d1 = decoder_block(b1, s4, 512)
    d2 = decoder_block(d1, s3, 256)
    d3 = decoder_block(d2, s2, 128)
    d4 = decoder_block(d3, s1, 64)

    activation = 'sigmoid'
    outputs = Conv3D(n_classes, 1, padding="same", activation=activation)(d4)  #Change the activation based on n_classes
   
    model = Model(inputs, outputs, name="U-Net")
    return model

my_model = build_unet((128, 128, 128 ,3), n_classes=3)

print(my_model.summary())

my_model.input_shape

np.unique(train_mask_cat
)

np.unique(train_mask_cat)

my_model.compile(optimizer = optim, loss=dice_coefficient_loss, metrics=dice_coefficient)
print(my_model.summary())

history = my_model.fit(X_train, y_train, 
                    batch_size = 1 , 
                    verbose=1, 
                    epochs=80, 
                    
                    validation_data=(X_test, y_test), 
                    
                    shuffle=False)

my_model.save('/content/drive/MyDrive/Colab Notebooks/saved_models/heartseg.h5')
my_model.save_weights('/content/drive/MyDrive/Colab Notebooks/saved_models/heartseg.hdf5')

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['dice_coefficient']
val_acc = history.history['val_dice_coefficient']

plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

from keras.models import load_model
my_model = load_model('/content/drive/MyDrive/Colab Notebooks/saved_models/heartseg.h5', compile=False)

y_pred=my_model.predict(X_test)
y_pred_argmax=np.argmax(y_pred, axis=4)
y_test_argmax = np.argmax(y_test, axis=4)

print(y_pred_argmax.shape)
print(y_test_argmax.shape)
print(np.unique(y_pred_argmax))

from keras.metrics import MeanIoU
from keras.metrics import MeanIoU
n_classes = 3
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_test_argmax, y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())

import random
test_img_number = random.randint(0, len(X_test))
test_img = X_test[test_img_number]
ground_truth=y_test[test_img_number]

test_img_input=np.expand_dims(test_img, 0)


test_pred = my_model.predict(test_img_input)
test_prediction = np.argmax(test_pred, axis=4)[0,:,:,:]

ground_truth_argmax = np.argmax(ground_truth, axis=3)
print(ground_truth_argmax.shape)

slice = random.randint(0, ground_truth_argmax.shape[2]-1)
plt.figure(figsize=(12, 8))
plt.subplot(231)
plt.title('Testing Image')
plt.imshow(test_img[slice,:,:,0], cmap='gray')
plt.subplot(232)
plt.title('Testing Label')
plt.imshow(ground_truth_argmax[slice,:,:])
plt.subplot(233)
plt.title('Prediction on test image')
plt.imshow(test_prediction[slice,:,:])
plt.show()



