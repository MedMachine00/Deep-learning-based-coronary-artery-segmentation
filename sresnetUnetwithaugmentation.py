# -*- coding: utf-8 -*-
"""Copy of Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f2W5GwjI7dM-m30Th9ly4xvo6fFN9VzY
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Heartloc3d

import tensorflow as tf

import keras
print(tf.__version__)
print(keras.__version__)

pip install segmentation_models_3D

import segmentation_models_3D as sm

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from skimage import io
import numpy as np
from matplotlib import pyplot as plt
from keras import backend as K
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

import os

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = io.imread(os.path.join(folder,filename))
        
        if img is not None:
            images.append(img)
    return images

def load_masks_from_folder(folder):
    masks = []
    for filename in os.listdir(folder):
        img = io.imread(os.path.join(folder,filename))
        if img is not None:
            masks.append(img)
    return masks

pip install SimpleITK

import SimpleITK as sitk

load_images_from_folder('/content/drive/MyDrive/Heartloc3d/train/images')

images = load_images_from_folder('/content/drive/MyDrive/Heartloc3d/train/images')

masks = load_masks_from_folder('/content/drive/MyDrive/Heartloc3d/train/masks')

images = np.asarray(images, dtype='int16')

masks = np.asarray(masks, dtype='int16')

np.unique(masks)

print(images.shape)

print(masks.shape)

pip install volumentations-3D

from volumentations import *



patch_size = 128

augment =  Compose([
       # Resize(patch_size, always_apply=True),
        #CropNonEmptyMaskIfExists(patch_size, always_apply=True),
        #Normalize(always_apply=True),
        ElasticTransform((0, 0.15)),
        Rotate((-15,15),(-15,15),(-15,15)),
        #Flip(0),
        #Flip(1),
        #Flip(2),
        Transpose((1,0,2)), # need patch.height = patch.width
        #RandomRotate90((0,1)),
        #RandomGamma(),
        GaussianNoise(),
        
    ], p=1)

augmentM =  Compose([
       # Resize(patch_size, always_apply=True),
        #CropNonEmptyMaskIfExists(patch_size, always_apply=True),
        #Normalize(always_apply=True),
        ElasticTransform((0, 0.15)),
        Rotate((-15,15),(-15,15),(-15,15)),
        #Flip(0),
        #Flip(1),
        #Flip(2),
        Transpose((1,0,2)), # need patch.height = patch.width
        #RandomRotate90((0,1)),
        #RandomGamma(),
        GaussianNoise(),
    ], p=1)

def aug_fn(image):
    data = {"image":image}
    aug_data = augment(**data)
    aug_img = aug_data["image"]
    
    aug_img = np.asarray(aug_img, dtype = 'int32')
    
    
    return aug_img,

def aug_fnMsk(mask):
    data = {"mask":mask}
    aug_data = augmentM(**data)
    aug_mask = aug_data["mask"]
    
    aug_mask = np.asarray(aug_mask, dtype = 'int32')
    
    return aug_mask

augmented_masks = aug_fnMsk(masks)

augmented_mask = np.asarray(augmented_masks, dtype = 'float32')

augmented_images = aug_fn(images)

augmented_images = np.asarray(augmented_images , dtype = 'float32')

augmented_images = np.reshape(augmented_images, (17, 128, 128, 128))

training_imgs = sorted(images.tolist() + augmented_images.tolist())

training_imgs = np.asarray(training_imgs, dtype = 'float32')

training_masks = sorted(masks.tolist() + augmented_mask.tolist())

training_masks = np.asarray(training_masks, dtype = 'float32')

training_imgs.shape

from tensorflow.keras.utils import normalize

train_img = np.stack((training_imgs,)*3, axis=-1)

train_img.shape

n_classes = 3

train_mask_cat = to_categorical(training_masks, num_classes= 3)

train_mask_cat.shape

X_train, X_test, y_train, y_test = train_test_split(train_img, train_mask_cat, test_size = 0.25, random_state = 42)

y_train.shape

def dice_coefficient(y_true, y_pred):
    smoothing_factor = 1
    flat_y_true = K.flatten(y_true)
    flat_y_pred = K.flatten(y_pred)
    return (2. * K.sum(flat_y_true * flat_y_pred) + smoothing_factor) / (K.sum(flat_y_true) + K.sum(flat_y_pred) + smoothing_factor)

def dice_coefficient_loss(y_true, y_pred):
    return 1 - dice_coefficient(y_true, y_pred)

patch_size = 128
channels=3


optim = tf.keras.optimizers.Adam()

#from sklearn.utils import class_weight
#class_weights = class_weight.compute_class_weight('balanced',
                                                 classes = np.unique(train_masks_reshaped_encoded),
                                                 y = train_masks_reshaped_encoded)
#print("Class weights are...:", class_weights)

encoder_weights = 'imagenet'
BACKBONE = 'vgg19'  #Try vgg16, efficientnetb7, inceptionv3, resnet50
activation = 'softmax'
patch_size = 128
n_classes = 3
channels=3

LR = 0.001
optim = tf.keras.optimizers.Adam(LR)


dice_loss = sm.losses.DiceLoss()
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)



metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]

preprocess_input = sm.get_preprocessing(BACKBONE)

X_train_prep = preprocess_input(X_train)
X_test_prep = preprocess_input(X_test)

model = sm.Unet(BACKBONE, classes=n_classes, 
                input_shape=(patch_size, patch_size, patch_size, channels), 
                encoder_weights=encoder_weights,
                activation=activation)

model.compile(optimizer = optim, loss= sm.losses.categorical_crossentropy , metrics=metrics)
print(model.summary())

from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau, ModelCheckpoint

learning_rate_reduction = ReduceLROnPlateau(monitor='val_iou_score', patience = 10, verbose=1,factor=0.2, min_lr=0.0000005)
mcp_save = ModelCheckpoint('heartlocx.hdf5', save_best_only=True, monitor='val_loss', mode='min')

callbacks_list = [ learning_rate_reduction, mcp_save]

history=model.fit(X_train_prep, 
          y_train,
          batch_size=2, 
          epochs=100,
          verbose=1,
          validation_data=(X_test_prep, y_test), callbacks = callbacks_list)

'''print(model.input_shape)
print(X_train.shape)
print(model.output_shape)
print(y_train.shape)
print("-------------------")
print(X_train.max())  #Shpuld be 1 after scaling. If it shows 255, go back and normalize/scale inputs

model.save_weights('/content/drive/MyDrive/Colab Notebooks/saved_models/heartloc3.hdf5')

model.save('/content/drive/MyDrive/Colab Notebooks/saved_models/heartloc3.h5')

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history.history['iou_score']
val_acc = history.history['val_iou_score']

plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

from keras.models import load_model
my_model = load_model('/content/drive/MyDrive/Heartloc3d/heartlocx.hdf5', compile=False)

y_pred=my_model.predict(X_test_prep)
y_pred_argmax=np.argmax(y_pred, axis=4)
y_test_argmax = np.argmax(y_test, axis=4)

print(y_pred_argmax.shape)
print(y_test_argmax.shape)
print(np.unique(y_pred_argmax))

from keras.metrics import MeanIoU
from keras.metrics import MeanIoU
n_classes = 3
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_test_argmax, y_pred_argmax)
print("Mean IoU =", IOU_keras.result().numpy())

import random
test_img_number = random.randint(0, len(X_test))
test_img = X_test[test_img_number]
ground_truth=y_test[test_img_number]

test_img_input=np.expand_dims(test_img, 0)


test_pred = my_model.predict(test_img_input)
test_prediction = np.argmax(test_pred, axis=4)[0,:,:,:]

ground_truth_argmax = np.argmax(ground_truth, axis=3)
print(ground_truth_argmax.shape)

slice = random.randint(0, ground_truth_argmax.shape[2]-1)
plt.figure(figsize=(12, 8))
plt.subplot(231)
plt.title('Testing Image')
plt.imshow(test_img[slice,:,:,0], cmap='gray')
plt.subplot(232)
plt.title('Testing Label')
plt.imshow(ground_truth_argmax[slice,:,:])
plt.subplot(233)
plt.title('Prediction on test image')
plt.imshow(test_prediction[slice,:,:])
plt.show()



