# -*- coding: utf-8 -*-
"""autoencoderunet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jhACIyQjxVa024BQ4gIS_2T4OAmR1VUN
"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Activation, MaxPool3D, Concatenate

def conv_block(input, num_filters):
    x = Conv3D(num_filters, 3, padding="same")(input)
    x = BatchNormalization()(x)   
    x = Activation("selu")(x)

    x = Conv3D(num_filters, 3, padding="same")(x)
    x = BatchNormalization()(x)  
    x = Activation("selu")(x)

    return x



def encoder_block(input, num_filters):
    x = conv_block(input, num_filters)
    p = MaxPooling3D((2, 2, 2))(x)
    return x, p   



def decoder_block(input, num_filters):
    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding="same")(input)
    x = conv_block(x, num_filters)
    return x


def build_encoder(input_image):
    #inputs = Input(input_shape)
    s1, p1 = encoder_block(input_image, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)
    s5, p5 = encoder_block(p4, 1024)
    
    
    encoded = conv_block(p4, 2048) #Bridge
    
    return encoded

def build_decoder(encoded):
    d1 = decoder_block(encoded, 1024)
    d2 = decoder_block(d1, 512)
    d3 = decoder_block(d2, 256)
    d4 = decoder_block(d3, 128)
    d5 = decoder_block(d4, 64)
    decoded = Conv3D(3, 3, padding="same", activation="softmax")(d4)
    return decoded

def build_autoencoder(input_shape):
    input_img = Input(shape=input_shape)
    autoencoder = Model(input_img, build_decoder(build_encoder(input_img)))
    return(autoencoder)

    #model=build_autoencoder((17, 128, 128, 128, 3))
    #print(model.summary())


def decoder_block_for_unet(input, skip_features, num_filters):
    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding="same")(input)
    x = Concatenate()([x, skip_features])
    x = conv_block(x, num_filters)
    return x
 

def build_unet(input_shape, n_classes):
    inputs = Input(input_shape)

    s1, p1 = encoder_block(inputs, 64)
    s2, p2 = encoder_block(p1, 128)
    s3, p3 = encoder_block(p2, 256)
    s4, p4 = encoder_block(p3, 512)

    b1 = conv_block(p4, 1024) #Bridge

    d1 = decoder_block_for_unet(b1, s4, 512)
    d2 = decoder_block_for_unet(d1, s3, 256)
    d3 = decoder_block_for_unet(d2, s2, 128)
    d4 = decoder_block_for_unet(d3, s1, 64)

    activation = 'softmax'
    outputs = Conv3D(n_classes, 1, padding="same", activation=activation)(d4)  
   
    model = Model(inputs, outputs, name="U-Net")
    return model

n_classes = 3

pip install SimpleITK

import SimpleITK as sitk

from skimage import io
import numpy as np
from matplotlib import pyplot as plt
from tensorflow.keras import backend as K
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import os
import cv2

def load_images_from_folder(folder):
    images = []
    for filename in os.listdir(folder):
        img = io.imread(os.path.join(folder,filename))
       
       
        if img is not None:
            images.append(img)
    return images

def load_masks_from_folder(folder):
    masks = []
    for filename in os.listdir(folder):
        img = io.imread(os.path.join(folder,filename))
        
        if img is not None:
            masks.append(img)
    return masks

masks = load_masks_from_folder('/content/drive/MyDrive/Heartloc3d/train/masks')

images = load_images_from_folder('/content/drive/MyDrive/Heartloc3d/train/images')

images = np.asarray(images, dtype='uint16')

masks = np.asarray(masks, dtype='uint16')

from tensorflow.keras.utils import normalize

import tensorflow as tf

patch_size = 128

pip install volumentations-3D

from volumentations import *

augment =  Compose([
       # Resize(patch_size, always_apply=True),
        #CropNonEmptyMaskIfExists(patch_size, always_apply=True),
        #Normalize(always_apply=True),
        ElasticTransform((0, 0.12)),
        Rotate((-10,10),(-10,10),(-10,10)),
        Flip(0),
        Flip(1),
        Flip(2),
        Transpose((1,0,2)), # need patch.height = patch.width
        #RandomRotate90((0,1)),
        RandomGamma(),
        GaussianNoise(),
        
    ], p=1)

augmentM =  Compose([
       # Resize(patch_size, always_apply=True),
        #CropNonEmptyMaskIfExists(patch_size, always_apply=True),
        #Normalize(always_apply=True),
        ElasticTransform((0, 0.12)),
        Rotate((-10,10),(-10,10),(-10,10)),
        Flip(0),
        Flip(1),
        Flip(2),
        Transpose((1,0,2)), # need patch.height = patch.width
        #RandomRotate90((0,1)),
        RandomGamma(),
        GaussianNoise(),
    ], p=1)

def aug_fn(image):
    data = {"image":image}
    aug_data = augment(**data)
    aug_img = aug_data["image"]
    
    aug_img = np.asarray(aug_img, dtype = 'int32')
    
    
    return aug_img,

def aug_fnMsk(mask):
    data = {"mask":mask}
    aug_data = augmentM(**data)
    aug_mask = aug_data["mask"]
    
    aug_mask = np.asarray(aug_mask, dtype = 'int32')
    
    return aug_mask

augmented_masks = aug_fnMsk(masks)

augmented_mask = np.asarray(augmented_masks, dtype = 'float32')

augmented_images = aug_fn(images)

augmented_images = np.asarray(augmented_images , dtype = 'float32')

augmented_images = np.reshape(augmented_images, (17, 128, 128, 128))

plt.imshow(augmented_images[12,:,:,42])

training_imgs = sorted(images.tolist() + augmented_images.tolist())

training_imgs = np.asarray(training_imgs, dtype = 'float32')

training_masks = sorted(masks.tolist() + augmented_mask.tolist())

training_masks = np.asarray(training_masks, dtype = 'float32')

train_img = np.stack((training_imgs ,)*3, axis=-1)
train_img = tf.keras.utils.normalize(train_img)

train_img = np.asarray(train_img, dtype = 'uint8')

train_img.shape

np.unique(masks
          )

train_mask_cat = to_categorical(training_masks, num_classes= 3)

train_mask_cat = np.asarray(train_mask_cat, dtype = 'uint8')

train_mask_cat.shape

autoencoder_model=build_autoencoder(( 128, 128, 128, 3))
autoencoder_model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])
print(autoencoder_model.summary())

train_img.dtype

!nvidia-smi

history = autoencoder_model.fit(train_img, train_img, batch_size =1,
        epochs=60, verbose=1)

#from keras.models import load_model
autoencoder_model = load_model("autoencoder_heartseg.h5", compile=False)
       
#Now define encoder model only, without the decoder part. 
input_shape = (128, 128, 128, 3)
input_img = Input(shape=input_shape)

encoder = build_encoder(input_img)
encoder_model = Model(input_img, encoder)
print(encoder_model.summary())

num_encoder_layers = len(encoder_model.layers) #35 layers in our encoder. 

#Get weights for the 35 layers from trained autoencoder model and assign to our new encoder model 
for l1, l2 in zip(encoder_model.layers[:35], autoencoder_model.layers[0:35]):
    l1.set_weights(l2.get_weights())

#Verify if the weights are the same between autoencoder and encoder only models. 
autoencoder_weights = autoencoder_model.get_weights()[0][1]
encoder_weights = encoder_model.get_weights()[0][1]

#Save encoder weights for future comparison
np.save('pretrained_encoder-weights.npy', encoder_weights )

input_shape = (128, 128, 128, 3)
#Then load weights from the original autoencoder for the first 35 layers (encoder)
unet_model = build_unet((128, 128, 128, 3), 3)

#Print layer names for each model to verify the layers....
#First 35 layers should be the same in both models. 
unet_layer_names=[]
for layer in unet_model.layers:
    unet_layer_names.append(layer.name)

autoencoder_layer_names = []
for layer in autoencoder_model.layers:
    autoencoder_layer_names.append(layer.name)
    
#Make sure the first 35 layers are the same. Remember that the exct names of the layers will be different.
###########

#Set weights to encoder part of the U-net (first 35 layers)
for l1, l2 in zip(unet_model.layers[:35], autoencoder_model.layers[0:35]):
    l1.set_weights(l2.get_weights())

from tensorflow.keras.optimizers import Adam
import segmentation_models as sm
unet_model.compile('Adam', loss=sm.losses.categorical_focal_jaccard_loss, metrics=[sm.metrics.iou_score])
#unet_model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])
unet_model.summary()
print(unet_model.output_shape)

unet_model.save('unet_model_weights.h5')

X_train, X_test, y_train, y_test = train_test_split(train_img, train_mask_cat, test_size = 0.2, random_state = 29)

unet_model.fit(X_train, y_train, 
                    verbose=1,
                    batch_size = 1,
                    validation_data=(X_test, y_test ), 
                    shuffle=False,
                    epochs=100)

unet_model.save_weights('unet_model_weights.hdf5')

gpu_info = !nvidia-smi
gpu_info = '\n'.join(gpu_info)
if gpu_info.find('failed') >= 0:
  print('Not connected to a GPU')
else:
  print(gpu_info)